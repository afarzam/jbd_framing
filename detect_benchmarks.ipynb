{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e135a036",
   "metadata": {},
   "source": [
    "# Detect Benchmarks – JBShield vs NSP\n",
    "*Runs with the same YAML you used for training / NSP.*\n",
    "\n",
    "**Usage inside notebook**\n",
    "1. Edit the `ARGS` dict in **Cell 2** below (cfg path, run-ID, method).\n",
    "2. Run all cells.  \n",
    "3. Results saved under `output/` & metrics printed in the log cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180abdab",
   "metadata": {},
   "source": [
    "## 0. Setup, Imports, & Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e18b5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.chdir(\"/mnt/home/amir/framingdecomp/framingDecomp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ae6b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices visible: 7\n",
      "torch.cud:a.device_count(): 1\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure there are multiple gpus available\n",
    "import torch, os\n",
    "print(\"Devices visible:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "print(\"torch.cud:a.device_count():\", torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b94d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: ## 0. Setup, Imports, & Globals\n",
    "\n",
    "# %%\n",
    "from __future__ import annotations\n",
    "import argparse, logging, sys, time, json, random\n",
    "from pathlib import Path\n",
    "import yaml, numpy as np, torch\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score,\n",
    "                             precision_recall_fscore_support)\n",
    "\n",
    "# our libs\n",
    "from utils.model_utils import load_model\n",
    "from models.encoder   import HFEncoder_notPooled\n",
    "from models.decomposer import NonlinearDecomposer_tiny\n",
    "from benchmarks.jbshield_core import JBShieldDetector\n",
    "from jailbreak_detect_nsp import _evaluate, detect_worker as nsp_worker\n",
    "\n",
    "LOGGER_NAME = \"detect_benchmarks_nb\"\n",
    "RESULTS = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3957c8",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Notebook Arguments  \n",
    "*(Edit and re-run this cell each time you want a different run.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4192acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: ## 1. Notebook Arguments  \n",
    "# *(Edit and re-run this cell each time you want a different run.)*\n",
    "\n",
    "ARGS = {\n",
    "    \"cfg_path\":       \"configs/jb_detect.yaml\",\n",
    "    \"dec_unique_id\":  \"20250717_101812_06190f25-e1f1-4ed4-87ae-a51365b6061b\",\n",
    "    \"model\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    \"cfg_unique_id\":  None,          # ← usually same as dec_unique_id\n",
    "    \"method\":         \"jbshield\",    # \"jbshield\" or \"nsp\"\n",
    "    \"batch_size\":     32,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb083904",
   "metadata": {},
   "source": [
    "## 2. Helper – JSONL Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fe8e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: ## 2. Helper – JSONL Loader\n",
    "\n",
    "\n",
    "def load_jsonl(path: str):\n",
    "    with open(path) as f:\n",
    "        return [json.loads(l) for l in f if l.strip() and not l.startswith(\"#\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b982ace",
   "metadata": {},
   "source": [
    "## 3. Set Up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2497dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detect_benchmarks_nb:Log → logs/detect_jbshield_20250722_194540_20250717_101812_06190f25-e1f1-4ed4-87ae-a51365b6061b.log\n"
     ]
    }
   ],
   "source": [
    "# Cell: ## 3. Set Up Logging\n",
    "\n",
    "Path(\"logs\").mkdir(exist_ok=True)\n",
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = Path(f\"logs/detect_{ARGS['method']}_{ts}_{ARGS['dec_unique_id']}.log\")\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s — %(levelname)s — %(message)s\",\n",
    "                    handlers=[logging.StreamHandler(sys.stdout),\n",
    "                              logging.FileHandler(log_file, mode=\"w\")])\n",
    "logger = logging.getLogger(LOGGER_NAME)\n",
    "logger.info(\"Log → %s\", log_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39972077",
   "metadata": {},
   "source": [
    "## 4. Load Config & Dataset Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c76ec702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detect_benchmarks_nb:Method: jbshield   | Encoder: meta-llama/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFG['data']  → {'input_path_varyFraming_id': './data/populated_artifacts/PAIR/id/all_populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl', 'input_path_varyGoal_id': './data/populated_artifacts/PAIR/id/all_cleaned_populated_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl', 'input_path_varyFraming_benign_id': './data/populated_benign_JBB-behaviors/PAIR/id/populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl', 'input_path_varyGoal_benign_id': './data/populated_benign_JBB-behaviors/PAIR/id/cleaned_populated_benign_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl', 'input_path_varyFraming_ood': './data/populated_artifacts/PAIR/ood/all_populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl', 'input_path_varyGoal_ood': './data/populated_artifacts/PAIR/ood/all_cleaned_populated_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl', 'input_path_varyFraming_benign_ood': './data/populated_benign_JBB-behaviors/PAIR/ood/populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl', 'input_path_varyGoal_benign_ood': './data/populated_benign_JBB-behaviors/PAIR/ood/cleaned_populated_benign_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl'}\n",
      "input_path_varyFraming_id: './data/populated_artifacts/PAIR/id/all_populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n",
      "input_path_varyGoal_id: './data/populated_artifacts/PAIR/id/all_cleaned_populated_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n",
      "input_path_varyFraming_benign_id: './data/populated_benign_JBB-behaviors/PAIR/id/populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n",
      "input_path_varyGoal_benign_id: './data/populated_benign_JBB-behaviors/PAIR/id/cleaned_populated_benign_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n",
      "input_path_varyFraming_ood: './data/populated_artifacts/PAIR/ood/all_populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n",
      "input_path_varyGoal_ood: './data/populated_artifacts/PAIR/ood/all_cleaned_populated_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n",
      "input_path_varyFraming_benign_ood: './data/populated_benign_JBB-behaviors/PAIR/ood/populated_prompts_gpt4.1_paraphrases10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n",
      "input_path_varyGoal_benign_ood: './data/populated_benign_JBB-behaviors/PAIR/ood/cleaned_populated_benign_prompts_gpt4.1_goals10_maxattempts5_noParaphrase.jsonl'  (type=<class 'str'>)\n"
     ]
    }
   ],
   "source": [
    "# Cell: ## 4 · Load Config & Dataset Splits\n",
    "\n",
    "with open(ARGS[\"cfg_path\"]) as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "\n",
    "# ---------- model name & (optional) decomposer config ----------\n",
    "if ARGS[\"method\"] == \"nsp\":\n",
    "    # NSP needs the encoder name from the training-phase config\n",
    "    if ARGS[\"cfg_unique_id\"] is None:\n",
    "        ARGS[\"cfg_unique_id\"] = ARGS[\"dec_unique_id\"]   # must be provided\n",
    "    with open(f\"output/config_{ARGS['cfg_unique_id']}.yaml\") as f:\n",
    "        CFG_OUT = yaml.safe_load(f)\n",
    "    enc_name = CFG_OUT[\"model\"][\"name\"]\n",
    "else:                     # JBShield\n",
    "    enc_name = CFG[\"model\"][\"name\"]        # read directly from main YAML\n",
    "\n",
    "# ---------- dataset splits (same for both detectors) ----------\n",
    "paths = CFG[\"data\"]\n",
    "print(\"CFG['data']  →\", CFG[\"data\"])\n",
    "for k, v in CFG[\"data\"].items():\n",
    "    print(f\"{k}: {v!r}  (type={type(v)})\")\n",
    "# AR = {k: load_jsonl(v) for k, v in paths.items()}\n",
    "AR = {\n",
    "    \"F_id\":  load_jsonl(paths[\"input_path_varyFraming_id\"]),\n",
    "    \"G_id\":  load_jsonl(paths[\"input_path_varyGoal_id\"]),\n",
    "    \"Fb_id\": load_jsonl(paths[\"input_path_varyFraming_benign_id\"]),\n",
    "    \"Gb_id\": load_jsonl(paths[\"input_path_varyGoal_benign_id\"]),\n",
    "    \"F_ood\": load_jsonl(paths[\"input_path_varyFraming_ood\"]),\n",
    "    \"G_ood\": load_jsonl(paths[\"input_path_varyGoal_ood\"]),\n",
    "    \"Fb_ood\":load_jsonl(paths[\"input_path_varyFraming_benign_ood\"]),\n",
    "    \"Gb_ood\":load_jsonl(paths[\"input_path_varyGoal_benign_ood\"]),\n",
    "}\n",
    "\n",
    "benign_id  = AR[\"Fb_id\"] + AR[\"Gb_id\"]\n",
    "jail_id    = AR[\"F_id\"]  + AR[\"G_id\"]\n",
    "m = min(len(benign_id), len(jail_id))\n",
    "benign_id, jail_id = random.sample(benign_id, m), random.sample(jail_id, m)\n",
    "\n",
    "benign_ood = AR[\"Fb_ood\"] + AR[\"Gb_ood\"]\n",
    "jail_ood   = AR[\"F_ood\"]  + AR[\"G_ood\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.info(\"Method: %s   | Encoder: %s\", ARGS[\"method\"], enc_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b68e25",
   "metadata": {},
   "source": [
    "## 5. JBShield Runner (if selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d23cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: ## 5. JBShield Runner (if selected)\n",
    "\n",
    "def run_jbshield(enc_name, ben_id, jb_id, ben_ood, jb_ood,\n",
    "                 batch_size, logger):\n",
    "    N_CAL = 100\n",
    "    cal_ben = random.sample([e[\"prompt\"] for e in ben_id], N_CAL)\n",
    "    cal_har = random.sample([e[\"prompt\"] for e in jb_id ], N_CAL)\n",
    "    cal_jb  = random.sample([e[\"prompt\"] for e in jb_id ], N_CAL)\n",
    "\n",
    "    det = JBShieldDetector(enc_name,\n",
    "                           device=device,\n",
    "                           batch_size=batch_size)\n",
    "    det.calibrate(cal_ben, cal_har, cal_jb)\n",
    "\n",
    "    for split_tag, B, J in [(\"ID\" , ben_id , jb_id ),\n",
    "                            (\"OOD\", ben_ood, jb_ood)]:\n",
    "        y_true = np.concatenate([np.zeros(len(B)), np.ones(len(J))])\n",
    "        preds  = det.predict([e[\"prompt\"] for e in B+J])\n",
    "        auroc  = roc_auc_score(y_true, preds)\n",
    "        acc    = accuracy_score(y_true, preds)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "                              y_true, preds, average=\"binary\", zero_division=0)\n",
    "        logger.info(\"%s  |  Acc %.3f  F1 %.3f  AUROC %.3f  Prec %.3f  Rec %.3f\",\n",
    "                    split_tag, acc, f1, auroc, prec, rec)\n",
    "        RESULTS.append({\"method\": \"jbshield\", \"split\": split_tag,\n",
    "                        \"acc\": acc, \"f1\": f1, \"auroc\": auroc,\n",
    "                        \"precision\": prec, \"recall\": rec})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79f1b7",
   "metadata": {},
   "source": [
    "## 6. Run Selected Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c4fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.model_utils:Loading model: meta-llama/Llama-2-7b-chat-hf on cuda\n",
      "/mnt/home/amir/jupyter-env/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/mnt/home/amir/jupyter-env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c848af1727aa4fd4910200a6c36e3c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jbshield:Calibrating JBShield-D …  |B|=100 |H|=100 |J|=100\n",
      "INFO:jbshield:Toxic concept layer = 6  (mean cosine 0.822)\n",
      "INFO:jbshield:JB concept layer   = 6  (mean cosine 0.823)\n",
      "INFO:jbshield:Thresholds  θ_t=-0.526  θ_j=0.535\n",
      "Predicting JBShield scores: 100%|██████████████████████████████████████████████████████████████████████████| 5124/5124 [05:37<00:00, 15.19it/s]\n",
      "INFO:detect_benchmarks_nb:ID  |  Acc 0.500  F1 0.000  AUROC 0.500  Prec 0.000  Rec 0.000\n",
      "Predicting JBShield scores: 100%|██████████████████████████████████████████████████████████████████████████| 1377/1377 [01:30<00:00, 15.27it/s]\n",
      "INFO:detect_benchmarks_nb:OOD  |  Acc 0.488  F1 0.000  AUROC 0.500  Prec 0.000  Rec 0.000\n"
     ]
    }
   ],
   "source": [
    "# Cell: ## 6. Run Selected Detector\n",
    "\n",
    "if ARGS[\"method\"] == \"jbshield\":\n",
    "    run_jbshield(enc_name, benign_id, jail_id, benign_ood, jail_ood,\n",
    "                 ARGS[\"batch_size\"], logger)\n",
    "else:\n",
    "    ckpt_dir = Path(\"checkpoints/decomposer_simple/\")\n",
    "    nsp_worker(device, enc_name, ckpt_dir,\n",
    "               benign_id, jail_id, benign_ood, jail_ood,\n",
    "               ARGS[\"batch_size\"], logger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84603b19",
   "metadata": {},
   "source": [
    "## 7. Save Metric JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b113928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:detect_benchmarks_nb:Saved metrics → output/detect_metrics_jbshield_1753205985.json\n"
     ]
    }
   ],
   "source": [
    "# Cell: ## 7. Save Metric JSON\n",
    "\n",
    "out_stub = f\"detect_metrics_{ARGS['method']}_{int(time.time())}.json\"\n",
    "out_path = Path(\"output\") / out_stub\n",
    "out_path.parent.mkdir(exist_ok=True)\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(RESULTS, f, indent=2)\n",
    "logger.info(\"Saved metrics → %s\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11122c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Venv",
   "language": "python",
   "name": "mykernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
